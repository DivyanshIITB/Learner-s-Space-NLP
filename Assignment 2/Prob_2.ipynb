{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab7f88d6-0aa8-4562-afe5-7d63b7030d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\divya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\divya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\divya/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# twitter_sentiment_classifier.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba666f9-c77c-478d-896e-c3a0e97fb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load data, rename text → 'Tweet', sentiment → label\n",
    "df = pd.read_csv('Tweets.csv')\n",
    "df = df[['airline_sentiment', 'text']].rename(columns={'airline_sentiment':'Label','text':'Tweet'})\n",
    "df = df[df['Label'].isin(['positive', 'negative', 'neutral'])]\n",
    "\n",
    "# 2. Preprocess each tweet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "contraction_replacements = { \"don't\":\"do not\", \"can't\":\"can not\", \"it's\":\"it is\", \"i'm\":\"i am\" }\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = text.lower()\n",
    "    for c, r in contraction_replacements.items():\n",
    "        text = text.replace(c, r)\n",
    "    text = re.sub(r\"http\\S+|@\\w+|#\\w+\", ' ', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return [lemmatizer.lemmatize(tok) for tok in tokens if tok.isalpha()]\n",
    "\n",
    "df['tokens'] = df['Tweet'].map(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27d945-15a1-4ccf-8bd0-6aebe559fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Load the pre-trained Google News Word2Vec model\n",
    "w2v_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aebc25f-4358-4c4f-a158-1eebb10cfeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divya\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Sentiment Accuracy: 0.7859\n"
     ]
    }
   ],
   "source": [
    "# 4. Tweet → average embeddings\n",
    "def tokens_to_vec(tokens, model, size=300):\n",
    "    vecs = [model[w] for w in tokens if w in model]\n",
    "    return np.mean(vecs, axis=0) if vecs else np.zeros(size)\n",
    "\n",
    "df['vec'] = df['tokens'].map(lambda toks: tokens_to_vec(toks, w2v_model))\n",
    "\n",
    "# 5. Train/test split\n",
    "X = np.vstack(df['vec'].values)\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Train & evaluate\n",
    "clf = LogisticRegression(max_iter=1000, multi_class='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "acc2 = clf.score(X_test, y_test)\n",
    "print(f\"Twitter Sentiment Accuracy: {acc2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22df3e76-f012-496e-9605-f292f130fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Prediction function\n",
    "def predict_tweet_sentiment(model, w2v_model, tweet):\n",
    "    tokens = clean_tweet(tweet)\n",
    "    vec = tokens_to_vec(tokens, w2v_model).reshape(1,-1)\n",
    "    return model.predict(vec)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8fa1456-8c24-4925-81d2-57cb8141cb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: This is the worst experience I've ever had with an airline. Never flying again!\n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Tweet: Amazing service and very friendly crew. Loved flying with you!\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Tweet: I will be flying with United Airlines tomorrow.\n",
      "Predicted Sentiment: neutral\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Negative Sentiment Tweet\n",
    "tweet1 = \"This is the worst experience I've ever had with an airline. Never flying again!\"\n",
    "prediction1 = predict_tweet_sentiment(clf, w2v_model, tweet1)\n",
    "print(f\"Tweet: {tweet1}\\nPredicted Sentiment: {prediction1}\\n\")\n",
    "\n",
    "# Example 2: Positive Sentiment Tweet\n",
    "tweet2 = \"Amazing service and very friendly crew. Loved flying with you!\"\n",
    "prediction2 = predict_tweet_sentiment(clf, w2v_model, tweet2)\n",
    "print(f\"Tweet: {tweet2}\\nPredicted Sentiment: {prediction2}\\n\")\n",
    "\n",
    "# Example 3: Neutral Sentiment Tweet\n",
    "tweet3 = \"I will be flying with United Airlines tomorrow.\"\n",
    "prediction3 = predict_tweet_sentiment(clf, w2v_model, tweet3)\n",
    "print(f\"Tweet: {tweet3}\\nPredicted Sentiment: {prediction3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40de8a2-4b3d-4562-8451-ae6e80707722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafdcb09-57de-420d-95ed-86adf3ff5f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
